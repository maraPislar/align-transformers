{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdd10dd",
   "metadata": {},
   "source": [
    "### Only for Dev\n",
    "\n",
    "If you are debugging this library or developing some new features, please don't imports as in other tutorials as they can load the pyvene library installed in your local env without your code updates.\n",
    "\n",
    "**Note**: If is better to remove your local pyvene pip install before dev."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcabbe",
   "metadata": {},
   "source": [
    "**Never Imports Like This**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5fd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     # This library is our indicator that the required installs\n",
    "#     # need to be done.\n",
    "#     import pyvene\n",
    "\n",
    "# except ModuleNotFoundError:\n",
    "#     !pip install git+https://github.com/frankaging/pyvene.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a689eb",
   "metadata": {},
   "source": [
    "**Do Relative Imports Instead**\n",
    "\n",
    "This way your updated code will be loaded instead of using your installed pyvene library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82271531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from pyvene.models.basic_utils import (\n",
    "    embed_to_distrib,\n",
    "    top_vals,\n",
    "    format_token,\n",
    "    count_parameters\n",
    ")\n",
    "\n",
    "from pyvene.models.gpt2.modelings_intervenable_gpt2 import create_gpt2\n",
    "\n",
    "from pyvene.models.intervenable_base import IntervenableModel\n",
    "from pyvene.models.interventions import VanillaIntervention\n",
    "\n",
    "from pyvene.models.configuration_intervenable_model import (\n",
    "    IntervenableConfig, IntervenableRepresentationConfig, VanillaIntervention)\n",
    "\n",
    "config, tokenizer, gpt = create_gpt2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a297602",
   "metadata": {},
   "source": [
    "**tensor versioning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e58e4a",
   "metadata": {},
   "source": [
    "when a tensor is created, its `_version` is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ec129",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,3)\n",
    "b = torch.rand(3,3)\n",
    "w = torch.rand(3,3)\n",
    "a._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38882c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8862658f",
   "metadata": {},
   "source": [
    "if there is any in-place op on this tensor, the `_version` number will increment by 1 for each op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8377b957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0] = 0\n",
    "b[0,0] = 0\n",
    "a._version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff175e6",
   "metadata": {},
   "source": [
    "for op that does not have side-effect (i.e., directly return), it creats new tensors, thus the `_version` for the output is 0 again, since it is a new tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7dab9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(w @ a)._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f34522c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b @ a)._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaf33957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.clone()._version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5bee1",
   "metadata": {},
   "source": [
    "**hook fail safe**\n",
    "\n",
    "if your hook ends up causing downstream calculation error, pytorch will actually absorb it and remove the hook. so, you need to be careful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd4ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1888,  0.3058]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = SimpleNet()\n",
    "    \n",
    "def output_str(self, input, output):\n",
    "    output = \"hey!\"\n",
    "\n",
    "# Step 3: Attach the Hook to a Layer\n",
    "hook = net.fc1.register_forward_hook(output_str)\n",
    "\n",
    "# Step 4: Run a Forward Pass\n",
    "input = torch.randn(1, 10)\n",
    "output = net(input)\n",
    "\n",
    "# Remove the hook if it's no longer needed\n",
    "hook.remove()\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
